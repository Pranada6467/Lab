{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install pyspark\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|number|square|\n",
      "+------+------+\n",
      "|     1|   1.0|\n",
      "|     2|   4.0|\n",
      "|     3|   9.0|\n",
      "|     4|  16.0|\n",
      "|     5|  25.0|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Square Integers Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data: a list of integers\n",
    "data = [(1,), (2,), (3,), (4,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Add a new column with the square of each integer\n",
    "df_squared = df.withColumn(\"square\", col(\"number\") ** 2)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_squared.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value is: 8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Find Maximum Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data: a list of integers\n",
    "data = [(1,), (3,), (2,), (8,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Find the maximum value in the \"number\" column\n",
    "max_value = df.select(max(\"number\")).collect()[0][0]\n",
    "\n",
    "# Print the maximum value\n",
    "print(f\"The maximum value is: {max_value}\")\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average value is: 3.8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Find Average Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data: a list of integers\n",
    "data = [(1,), (3,), (2,), (8,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Calculate the average of the \"number\" column\n",
    "average_value = df.select(avg(\"number\")).collect()[0][0]\n",
    "\n",
    "# Print the average value\n",
    "print(f\"The average value is: {average_value}\")\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...| 930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...| 821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...|  84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...|  25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...| 832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...|  55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|   7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...|  30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...| 147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|    269|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H14|Salaries and wage...|Financial perform...|   1639|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H19|Purchases and oth...|Financial perform...| 566979|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H20|Non-operating exp...|Financial perform...|  23176|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H21|      Opening stocks|Financial perform...|  80778|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H22|      Closing stocks|Financial perform...|  88197|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H23|Surplus before in...|Financial perform...| 105450|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H24|        Total assets|  Financial position|2831894|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H25|      Current assets|  Financial position| 861255|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H26|Fixed tangible as...|  Financial position| 681890|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H29|        Other assets|  Financial position|1288749|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = \"/home/lplab/Documents/220962085_BDA/Week1\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  1|Alice| 29|\n",
      "|  2|  Bob| 31|\n",
      "|  3|Cathy| 25|\n",
      "+---+-----+---+\n",
      "\n",
      "Schema of the DataFrame:\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Display DataFrame Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, \"Alice\", 29), (2, \"Bob\", 31), (3, \"Cathy\", 25)]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows:\")\n",
    "df.show()  # By default, shows the first 20 rows\n",
    "\n",
    "# Display the schema of the DataFrame\n",
    "print(\"Schema of the DataFrame:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|                 5|\n",
      "|   mean|              32.0|\n",
      "| stddev|5.7445626465380295|\n",
      "|    min|                25|\n",
      "|    max|                40|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, \"Alice\", 29), (2, \"Bob\", 31), (3, \"Cathy\", 25), (4, \"David\", 40), (5, \"Eve\", 35)]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Calculate summary statistics for the 'age' column\n",
    "summary_stats = df.describe(\"age\")\n",
    "\n",
    "# Show the summary statistics\n",
    "summary_stats.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
